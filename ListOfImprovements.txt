 -- TO DO --
* COMMENT THE SCRIPTS
* Add sweeproot.C to our script to validate ntuples as they come out.
* Remove merging step. Just skim. This will mean that there will be more and smaller files on hadoop (pre-skim).
* Change scripts to do skimming on the cluster and use xrdcp to copy the files off of it.
* make a seperate .C file to do merging, call it from shell script instead of printing it out???
* in merging use libminifwlite, or if can't find use fwlite from CMSSW environ if set, or if neither throw an error
* Modify compareGoodRun2Data.py to take a run range to do the comparison within. We can add missing lumi sections and run numbers to the monitoring page (I know this isn't entirely accurate, but is still a nice cross check to have).
* Add option to use xrootd or use a local accessor.
* Expand ntupling to use more sites than just ucsd (not entirely sure what is involved in this, but i think will be complex). Use only reliable sites.
* Add a progress log to monitoring website (will list number of files ntupled, number of files running, number of files, skimmed, number of files checked by sweeproot.C). Ben will bother us less if we do this.
* Script to check log files for exceptions and report them on the monitoring site.
* Move all supporting scripts (like getLFNList.py, compareGoodRun2Data.py, ect) to a sub directory labeled "lib" or "scripts" or something.
* add argument to specify scram_arch in runfromonecfg.sh

 -- DONE --
* Add a configuration file with user set variables and the necessary script to read it and set variables so the users don't have to edit code to run it. Ian has already written this (not the python one, but a new bash one that can seemlessly be implemented in the bash code). It needs to be added into the scripts.
* Check for available disk space. Move and merge smartly. Before it will try to merge onto full disks. Must test for this and include error handling.
* Move all variables that need to be set by the user to run to the front of the script so they are easy to find.
* In the resubmit script don't use a python script to modify the command file, hard code into the bash script a way to do this.
* Replace the libMiniFWLite.so with a variable that can be set by the user. 
* Check if the specified configuration file Data*_cfg.py exists. Don't ntuple if it isn't in the folder. Throw a warning to the user.
* In checkAndSubmit.sh put the section that produces the .cmd file in it's own section. Ask Ian, he has this mostly written.
* In checkFailedJobs.sh, we don't need to check for each skim individually, we can put this in a loop and have a list of skims to check. Make this more general.
* Can probably do something like what is being done in 10 for checkAndRunSkim.sh
* Store .out/.err log files on /data/tmp so that they don't wast home space and so Terrence doesn't need to back them up.
* Add some lines to check for a valid user proxy. Ian has figured out why the environment variable isn't always set and how to check if it is set, and if not try to find where the proxy is stored. If the script can't find anything, it should warn the user that the users jobs may remain idle if submitted without a valid proxy.
* in skimming use libminifwlite, or if can't find use fwlite from CMSSW environ if set, or if neither throw an error
* in merging test for existence of libminifwlit. if it doesn't exist, exit.
* Change the max size of merged files to something managable, choose 8 Gb for now since I think the grid has a 10 Gb size limit for jobs. May want to revisit this.
* Check for available disk space. Move and skim smartly. Before it will try to skim onto full disks. Must test for this and include error handling.
* Change output path for the files. The CMSSW release and CMS2 tag appears in the path too many times.
          something like /hadoop/.../CMSSW_4_2_4/V04-02-22/Photon_Run2011A-PromptReco-v4_AOD/unmerged/
                         /hadoop/.../CMSSW_4_2_4/V04-02-22/Photon_Run2011A-PromptReco-v4_AOD/merged/
* Move the lines that create nfs dirs to allskim, move the lines that create merged dirs to checkAndMerge
* A script to create a new version of libMiniFWLite based on a CMSSW release and tag number.
